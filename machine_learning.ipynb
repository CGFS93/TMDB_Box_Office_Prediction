{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/machadolluis/miniforge3/envs/mlenv/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, BayesianRidge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Database into pandas DataFrame\n",
    "df_X = pd.read_sql(\"select budget,popularity from clean_kaggle\", con=engine)\n",
    "df_y = pd.read_sql(\"select revenue from clean_kaggle\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data features/targets into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features\n",
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictor Variable\n",
    "df_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the model\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Start Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.7589452623437296\n",
      "r-squared Score: 0.9992434463263903\n"
     ]
    }
   ],
   "source": [
    "# Check model scores\n",
    "# mean absolute error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "# median absolute error\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "# r2 score\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Median Absolute Error: {medae}\")\n",
    "print(f\"r-squared Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the model\n",
    "model = Ridge().fit(X_train, y_train)\n",
    "\n",
    "# Start Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.7589452623437296\n",
      "r-squared Score: 0.9992434463263903\n"
     ]
    }
   ],
   "source": [
    "# Check model scores\n",
    "# mean absolute error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "# median absolute error\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "# r2 score\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Median Absolute Error: {medae}\")\n",
    "print(f\"r-squared Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the model\n",
    "model = BayesianRidge().fit(X_train, y_train)\n",
    "\n",
    "# Start Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.7589452623437296\n",
      "r-squared Score: 0.9992434463263903\n"
     ]
    }
   ],
   "source": [
    "# Check model scores\n",
    "# mean absolute error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "# median absolute error\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "# r2 score\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Median Absolute Error: {medae}\")\n",
    "print(f\"r-squared Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate model \n",
    "model = RandomForestRegressor().fit(X_train,y_train)\n",
    "\n",
    "# Start Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.7589452623437296\n",
      "r-squared Score: 0.9992434463263903\n"
     ]
    }
   ],
   "source": [
    "# Check model scores\n",
    "# mean absolute error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "# median absolute error\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "# r2 score\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Median Absolute Error: {medae}\")\n",
    "print(f\"r-squared Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate model\n",
    "model = XGBRegressor().fit(X_train,y_train)\n",
    "\n",
    "# Start Prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.7589452623437296\n",
      "r-squared Score: 0.9992434463263903\n"
     ]
    }
   ],
   "source": [
    "# Check model scores\n",
    "# mean absolute error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "# median absolute error\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "# r2 score\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Median Absolute Error: {medae}\")\n",
    "print(f\"r-squared Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "\n",
    "After comparing each model's scores, we choose one for the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model = model(random_state = 16).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values\n",
    "y_pred_final = final_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008018475fc5ce7c4715d29dd4c0acd35a6ea114508362f4da4d62a22f71ab50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
